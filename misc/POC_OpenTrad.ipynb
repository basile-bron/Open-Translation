{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basile-bron/Open-Translation/blob/main/OpenTrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jYg86w-3umNl",
        "outputId": "3c2fdf79-e242-4440-f49a-161ffccb0bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=49c5edaa0012f5ab395274fff95b2d7c07e121d2712c799bf29903f70caa2491\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, pytesseract, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 pytesseract-0.3.10 rfc3986-1.5.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-jpn tesseract-ocr-osd\n",
            "0 upgraded, 4 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 6,206 kB of archives.\n",
            "After this operation, 18.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-jpn all 1:4.00~git30-7274cfa-1.1 [1,390 kB]\n",
            "Fetched 6,206 kB in 1s (5,404 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120511 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-jpn.\n",
            "Preparing to unpack .../tesseract-ocr-jpn_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-jpn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-jpn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-kor\n",
            "0 upgraded, 1 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 1,052 kB of archives.\n",
            "After this operation, 1,693 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-kor all 1:4.00~git30-7274cfa-1.1 [1,052 kB]\n",
            "Fetched 1,052 kB in 0s (3,699 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-kor.\n",
            "(Reading database ... 120562 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-kor_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-kor (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-kor (1:4.00~git30-7274cfa-1.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-jpn-vert\n",
            "0 upgraded, 1 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 1,889 kB of archives.\n",
            "After this operation, 3,053 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-jpn-vert all 1:4.00~git30-7274cfa-1.1 [1,889 kB]\n",
            "Fetched 1,889 kB in 0s (6,615 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-jpn-vert.\n",
            "(Reading database ... 120566 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-jpn-vert_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-jpn-vert (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-jpn-vert (1:4.00~git30-7274cfa-1.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package tesseract-lang\n",
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed Pillow-9.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google_trans_new\n",
            "  Downloading google_trans_new-1.1.9-py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: google_trans_new\n",
            "Successfully installed google_trans_new-1.1.9\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2023.7.22)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow pytesseract googletrans==4.0.0-rc1\n",
        "!sudo apt-get install tesseract-ocr-jpn\n",
        "!sudo apt-get install tesseract-ocr-kor\n",
        "!sudo apt-get install tesseract-ocr-jpn-vert\n",
        "!sudo apt-get install tesseract-lang\n",
        "\n",
        "!pip install Pillow==9.5.0\n",
        "\n",
        "!pip install google_trans_new\n",
        "!pip install -U deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHlgteHougPi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "from PIL import Image\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58gAev_IxVMD"
      },
      "outputs": [],
      "source": [
        "translator = Translator()\n",
        "\n",
        "class Blurb(object):\n",
        "    def __init__(self, x, y, w, h, text, confidence=100.0):\n",
        "      \"\"\"\n",
        "      Initialize a Blurb object.\n",
        "\n",
        "      Args:\n",
        "          x (int): X-coordinate of the top-left corner of the region.\n",
        "          y (int): Y-coordinate of the top-left corner of the region.\n",
        "          w (int): Width of the region.\n",
        "          h (int): Height of the region.\n",
        "          text (str): The actual text content within the region.\n",
        "          confidence (float, optional): Confidence level of the OCR system in recognizing the text content.\n",
        "                                        Defaults to 100.0.\n",
        "      \"\"\"\n",
        "      self.x = x\n",
        "      self.y = y\n",
        "      self.w = w\n",
        "      self.h = h\n",
        "      self.text = text\n",
        "      self.confidence = confidence\n",
        "\n",
        "    def clean_text(self):\n",
        "      \"\"\"\n",
        "      Clean the text content by removing newline characters.\n",
        "\n",
        "      Returns:\n",
        "          str: The cleaned text.\n",
        "      \"\"\"\n",
        "      text = self.text\n",
        "      text = re.sub(r\"\\n\", \"\", text)\n",
        "      \"\"\"\n",
        "      for letter in text:\n",
        "\n",
        "          if ord(letter) > 255:\n",
        "              #print(\"deleting atrocity\")\n",
        "              text = text.replace(letter, \"\")\n",
        "      \"\"\"\n",
        "\n",
        "      return text\n",
        "\n",
        "    def __str__(self):\n",
        "      \"\"\"\n",
        "      Return a string representation of the Blurb object.\n",
        "\n",
        "      Returns:\n",
        "          str: The string representation in the format: \"x,y w x h confidence%: text\".\n",
        "      \"\"\"\n",
        "      return str(self.x) + ',' + str(self.y) + ' ' + str(self.w) + 'x' + str(self.h) + ' ' + str(self.confidence) + '% :' + self.text\n",
        "\n",
        "\n",
        "class TranslatedBlurb(Blurb):\n",
        "    def __init__(self, x, y, w, h, text, confidence, translation):\n",
        "      \"\"\"\n",
        "      Initialize a TranslatedBlurb object.\n",
        "\n",
        "      Args:\n",
        "          x (int): X-coordinate of the top-left corner of the region.\n",
        "          y (int): Y-coordinate of the top-left corner of the region.\n",
        "          w (int): Width of the region.\n",
        "          h (int): Height of the region.\n",
        "          text (str): The actual text content within the region.\n",
        "          confidence (float): Confidence level of the OCR system in recognizing the text content.\n",
        "          translation (str): The translated text.\n",
        "      \"\"\"\n",
        "      Blurb.__init__(self, x, y, w, h, text, confidence)\n",
        "      self.translation = translation\n",
        "\n",
        "    @classmethod\n",
        "    def as_translated(cls, parent, translation):\n",
        "      \"\"\"\n",
        "      Create a new TranslatedBlurb object based on an existing Blurb object and a translation.\n",
        "\n",
        "      Args:\n",
        "          parent (Blurb): The parent Blurb object to inherit attributes from.\n",
        "          translation (str): The translated text.\n",
        "\n",
        "      Returns:\n",
        "          TranslatedBlurb: The new TranslatedBlurb object.\n",
        "      \"\"\"\n",
        "      return cls(parent.x, parent.y, parent.w, parent.h, parent.text, parent.confidence, translation)\n",
        "\n",
        "\n",
        "def translate_text(text):\n",
        "    \"\"\"\n",
        "    Translate the given text to English.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to be translated.\n",
        "\n",
        "    Returns:\n",
        "        str: The translated text in UTF-8 encoded format.\n",
        "    \"\"\"\n",
        "    #if isinstance(text,str):\n",
        "    translated_text = translator.translate(text, dest='fr')\n",
        "\n",
        "    return translated_text.text.encode('utf-8')\n",
        "\n",
        "\n",
        "def translate_blurb(blurb):\n",
        "    \"\"\"\n",
        "    Translate the text content of a Blurb object to English and create a TranslatedBlurb object.\n",
        "\n",
        "      Args:\n",
        "          blurb (Blurb): The Blurb object to be translated.\n",
        "\n",
        "      Returns:\n",
        "        blurb (Blurb): The Blurb object translated.\n",
        "    \"\"\"\n",
        "\n",
        "    translation = translate_text(blurb.clean_text())\n",
        "    return TranslatedBlurb.as_translated(blurb, translation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "3sopR7e1uXgE",
        "outputId": "1c894904-3817-4193-b8be-4d5df69ad06d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    Page segmentation modes:\\n      0    Orientation and script detection (OSD) only.\\n      1    Automatic page segmentation with OSD.\\n      2    Automatic page segmentation, but no OSD, or OCR.\\n      3    Fully automatic page segmentation, but no OSD. (Default)\\n      4    Assume a single column of text of variable sizes.\\n      5    Assume a single uniform block of vertically aligned text.\\n      6    Assume a single uniform block of text.\\n      7    Treat the image as a single text line.\\n      8    Treat the image as a single word.\\n      9    Treat the image as a single word in a circle.\\n    10    Treat the image as a single character.\\n    11    Sparse text. Find as much text as possible in no particular order.\\n    12    Sparse text with OSD.\\n    13    Raw line. Treat the image as a single text line,\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Page segmentation modes:\n",
        "      0    Orientation and script detection (OSD) only.\n",
        "      1    Automatic page segmentation with OSD.\n",
        "      2    Automatic page segmentation, but no OSD, or OCR.\n",
        "      3    Fully automatic page segmentation, but no OSD. (Default)\n",
        "      4    Assume a single column of text of variable sizes.\n",
        "      5    Assume a single uniform block of vertically aligned text.\n",
        "      6    Assume a single uniform block of text.\n",
        "      7    Treat the image as a single text line.\n",
        "      8    Treat the image as a single word.\n",
        "      9    Treat the image as a single word in a circle.\n",
        "    10    Treat the image as a single character.\n",
        "    11    Sparse text. Find as much text as possible in no particular order.\n",
        "    12    Sparse text with OSD.\n",
        "    13    Raw line. Treat the image as a single text line,\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GQdVDowuzlx"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "\n",
        "def flow_into_box(text, w, font, min_word_on_line=0.3):\n",
        "    \"\"\"\n",
        "    Formats the given text to fit within a specified width.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to format.\n",
        "        w (int): The width to fit the text into.\n",
        "        font (PIL.ImageFont.FreeTypeFont, optional): The font to use for measuring text width. Defaults to None.\n",
        "        min_word_on_line (float, optional): The minimum proportion of a word to be placed on a line. Defaults to 0.3.\n",
        "\n",
        "    Returns:\n",
        "        str: The formatted text with line breaks to fit within the specified width.\n",
        "    \"\"\"\n",
        "    if isinstance(text, bytes):\n",
        "      text = text.decode(\"utf-8\")\n",
        "\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "\n",
        "    for word in words:\n",
        "        if current_line:\n",
        "            \"\"\"\n",
        "            # Check if adding the next word exceeds the width limit\n",
        "            current_line_length = ImageDraw.textbbox((0, 0), \" \".join(current_line + [word]), font=font)[2]\n",
        "\n",
        "            #current_line_length = font.getsize(\" \".join(current_line + [word]))[0]\n",
        "            if current_line_length < w * (1 - min_word_on_line):\n",
        "                # Add the word to the current line\n",
        "                current_line.append(word)\n",
        "            else:\n",
        "              \"\"\"\n",
        "            # Start a new line\n",
        "            lines.append(\" \".join(current_line))\n",
        "            current_line = [word]\n",
        "        else:\n",
        "            # First word on the line\n",
        "            current_line.append(word)\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(\" \".join(current_line))\n",
        "\n",
        "    #print(lines)\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUjhsMKQOHWt"
      },
      "outputs": [],
      "source": [
        "def typeset_blurb(img, blurb):\n",
        "    if isinstance(blurb, TranslatedBlurb):\n",
        "        text = blurb.translation\n",
        "    else:\n",
        "      if isinstance(text, bytes):\n",
        "        text = text.decode(\"utf-8\")\n",
        "\n",
        "    if len(text) > 4:\n",
        "      area = blurb.w * blurb.h\n",
        "      fontsize = int(math.sqrt(area) / 10)\n",
        "      #usingFont = ImageFont.load_default()\n",
        "\n",
        "      usingFont = ImageFont.truetype(\"Arial.ttf\", fontsize)\n",
        "\n",
        "      flowed = flow_into_box(text, blurb.w, usingFont)\n",
        "      if flowed:\n",
        "        d = ImageDraw.Draw(img)\n",
        "\n",
        "        # size of the white box behind the translated text\n",
        "        filling = (255, 255, 255, 170)\n",
        "        ImageDraw.Draw(img, \"RGBA\").rounded_rectangle([(blurb.x, blurb.y), (blurb.x+blurb.w, blurb.y+blurb.h)], radius=25,\n",
        "                                                     fill=filling, width=0)\n",
        "        #img.paste((255, 255, 255, 128), (blurb.x, blurb.y, blurb.h, blurb.w))\n",
        "\n",
        "        #pasting the new text on the white out area\n",
        "        d.text((blurb.x, blurb.y), flowed.strip(), fill=(0, 0, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bcuc653UoI1L"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "def get_params():\n",
        "    params = \"\"\n",
        "    params += \"--psm 12\"\n",
        "\n",
        "    configParams = []\n",
        "    def configParam(param, val):\n",
        "      return \"-c \" + param + \"=\" + val\n",
        "    configParams.append((\"chop_enable\", \"T\"))\n",
        "    configParams.append(('use_new_state_cost','F'))\n",
        "    configParams.append(('segment_segcost_rating','F'))\n",
        "    configParams.append(('enable_new_segsearch','0'))\n",
        "    configParams.append(('textord_force_make_prop_words','F'))\n",
        "    configParams.append(('tessedit_char_blacklist', 'ㆍ@-ㅡ《0123456789}><~^/#'))\n",
        "    configParams.append(('textord_debug_tabfind','0'))\n",
        "    #configParams.append(('preserve_interword_spaces','1'))\n",
        "\n",
        "    params += \" \".join([configParam(p[0], p[1]) for p in configParams])\n",
        "    return params\n",
        "\n",
        "def get_blurbs(img):\n",
        "\n",
        "  # Convert the input image to grayscale\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Apply adaptive thresholding to create a binary image (black and white) using a Gaussian method.\n",
        "  # The thresholded image is then inverted using bitwise_not.\n",
        "  img_gray = cv2.bitwise_not(cv2.adaptiveThreshold(img_gray, 255, cv2.THRESH_BINARY, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 75, 10))\n",
        "\n",
        "  # Create a 2x2 kernel to be used for erosion operation\n",
        "  kernel = np.ones((2,2), np.uint8)\n",
        "\n",
        "  # Erode the image to remove noise and small details by applying the kernel repeatedly.\n",
        "  # This operation helps to make the text or blurb regions more distinguishable.\n",
        "  img_gray = cv2.erode(img_gray, kernel, iterations=2)\n",
        "\n",
        "  # Invert the image again to revert it back to the original orientation.\n",
        "  img_gray = cv2.bitwise_not(img_gray)\n",
        "\n",
        "  # Find contours in the processed image using RETR_TREE mode (hierarchical contour retrieval mode)\n",
        "  # and CHAIN_APPROX_SIMPLE method (compresses horizontal, vertical, and diagonal segments and leaves only their end points).\n",
        "  contours, hierarchy = cv2.findContours(img_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  # Create an empty mask image with the same dimensions as the input image.\n",
        "  mask = np.zeros_like(img)\n",
        "\n",
        "  # Convert the mask to grayscale (single-channel) for further processing.\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Get the height, width, and number of channels of the input image.\n",
        "  height, width, channel = img.shape\n",
        "\n",
        "  pruned_contours = []\n",
        "\n",
        "  for cnt in contours:\n",
        "    area = cv2.contourArea(cnt)\n",
        "    if area > 100 and area < ((height / 3) * (width / 3)):\n",
        "      pruned_contours.append(cnt)\n",
        "\n",
        "  # find contours for the mask for a second pass after pruning the large and small contours\n",
        "  cv2.drawContours(mask, pruned_contours, -1, (255,255,255), 1)\n",
        "  contours2, hierarchy = cv2.findContours(mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "  final_mask = cv2.cvtColor(np.zeros_like(img), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  blurbs = []\n",
        "  for cnt in contours2:\n",
        "    area = cv2.contourArea(cnt)\n",
        "    if area > 1000 and area < ((height / 3) * (width / 3)):\n",
        "      draw_mask = cv2.cvtColor(np.zeros_like(img), cv2.COLOR_BGR2GRAY)\n",
        "      approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
        "      #pickle.dump(approx, open(\"approx.pkl\", mode=\"w\"))\n",
        "      cv2.fillPoly(draw_mask, [approx], (255,0,0))\n",
        "      cv2.fillPoly(final_mask, [approx], (255,0,0))\n",
        "      image = cv2.bitwise_and(draw_mask, cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
        "      draw_mask_inverted = cv2.bitwise_not(draw_mask)\n",
        "      image = cv2.bitwise_or(image, draw_mask_inverted)\n",
        "      y = approx[:, 0, 1].min()\n",
        "      h = approx[:, 0, 1].max() - y\n",
        "      x = approx[:, 0, 0].min()\n",
        "      w = approx[:, 0, 0].max() - x\n",
        "      image = image[y:y+h, x:x+w]\n",
        "\n",
        "      padding = 10  # Number of pixels for padding\n",
        "\n",
        "      # Add padding to the image\n",
        "      image = np.pad(image, ((padding, padding), (padding, padding)), mode='constant', constant_values=255)\n",
        "\n",
        "\n",
        "      pil_image = Image.fromarray(image)\n",
        "      display(pil_image)\n",
        "\n",
        "      #OCR recognition\n",
        "      text = pytesseract.image_to_string(pil_image, lang=\"kor\", config=get_params())\n",
        "      text = text.replace(\"\\n\", \"\")\n",
        "      text = text.replace(\"\\x0c\", \"\")\n",
        "      display(text)\n",
        "      #Non UTF8 cleaner\n",
        "\n",
        "      if text and text.strip():\n",
        "        for letter in text:\n",
        "          if ord(letter) > 255:\n",
        "              #print(\"deleting atrocity\")\n",
        "              text = text.replace(letter, \"\")\n",
        "      if text and text.strip() and text != None:\n",
        "        #filter out noise under x characters\n",
        "        if len(text)>3:\n",
        "          blurb = Blurb(x, y, w, h, text)\n",
        "          #print(blurb)\n",
        "          blurbs.append(blurb)\n",
        "          #print (\"Attempt: \" + text + ' -> ' + str(translator.translate(text,dest='fr').text))\n",
        "\n",
        "  return blurbs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOzKD+6niGaGo6e4bqUJw7B",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
